Adversarial Example Generation:

First, create a directory named cifar-100_CW_mix and, within it, another directory named images.
To begin generating adversarial examples based on the C&W attack, execute the following command:

python cw_attack.py

The generated examples will be stored in the cifar-100_CW_mix/images folder.

Evaluation:

Create a directory named cifar-100_eval and, inside this directory, create another directory named images.
Place all the 500 CIFAR-100 evaluation images into this images directory.
To start the evaluation process, type the following comsmand:

python main.py -m <mode>

Here, -m specifies the mode, which can be cw or eval. 
The cw mode will test all the models against the dataset generated by the CW attack, 
while the eval mode will test them on the original evaluation set.